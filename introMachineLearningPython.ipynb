{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "introMachineLearningPython.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPoDOXzaFdxuCg3E8zIKJg4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amogh3892/3D-Biomedical-Image-Processing-Python-tutorial/blob/main/introMachineLearningPython.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7T7yz8iTC8T"
      },
      "source": [
        "# Introduction to Machine Learning using Python\n",
        "Biomedical Image Processing (EBME 361/461)\n",
        "\n",
        "**Amogh Hiremath**<br>\n",
        "*Graduate Research Assistant*<br> \n",
        "*Center of Computational Imaging and Personalized Diagnostics (CCIPD)*<br> \n",
        "*Case Western Reserve University*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OYw7yFteGyC"
      },
      "source": [
        "### Importing required libraries/modules\n",
        "\n",
        "The primary python package used for developing machine learning models in python is [scikit-learn](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning)\n",
        "\n",
        "Libraries such as pandas and numpy are particularly used to handle datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pECRrRKDTGf-"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import seaborn as sns\n",
        "%matplotlib inline \n",
        "import matplotlib.pyplot as plt\n",
        "!pip install statannot\n",
        "from statannot import add_stat_annotation\n",
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score, auc, plot_roc_curve"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPA3SSgNflzi"
      },
      "source": [
        "### Reading and exploring the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znsHKOZFfkGo"
      },
      "source": [
        "# Reading the csv file as a pandas dataframe\n",
        "df = pd.read_csv(\"prostateML.csv\")\n",
        "\n",
        "# Getting information of the dataset\n",
        "df.info()\n",
        "\n",
        "# Printing a few rows of the dataset\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ24qZ82f4jG"
      },
      "source": [
        "# Basic statistics of the dataset\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSUEX-IYntsu"
      },
      "source": [
        "# Class distribution in the dataset\n",
        "print(df.groupby('Label').size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_VtGY3tisB8"
      },
      "source": [
        "# Accessing a particular row; use iloc\n",
        "print(df.iloc[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmtSE2OujDTD"
      },
      "source": [
        "# Accessing specific columns in the dataframe;  \n",
        "print(df[[\"PatientID\",\"Feature_0\"]])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlweXr1rg8c-"
      },
      "source": [
        "# Example of filtering your dataset\n",
        "# For example, let's say you only want to consider rows/ here patients with Feature_0 value > 150\n",
        "\n",
        "print(f\"Total rows beforing filtering: {df.shape}\")\n",
        "\n",
        "filtereddf = df[df[\"Feature_0\"] > 150]\n",
        "\n",
        "print(f\"Total rows after filtering: {filtereddf.shape}\")\n",
        "\n",
        "print(filtereddf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmZ404YUlW-q"
      },
      "source": [
        "# Let's try to look at the histogram 5 different features\n",
        "df5 = df[[\"Feature_10\",\"Feature_20\",\"Feature_30\",\"Feature_40\",\"Feature_50\"]]\n",
        "df5.hist(figsize=(10, 8), bins=50, xlabelsize=8, ylabelsize=8);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9FDc4wnmAUu"
      },
      "source": [
        "# Looking at correlation between the features.\n",
        "\n",
        "corr = df5.corr()\n",
        "\n",
        "sns.heatmap(corr[(corr >= 0.5) | (corr <= -0.4)], \n",
        "            cmap='jet', vmax=1.0, vmin=-1.0, linewidths=0.1,\n",
        "            annot=True, annot_kws={\"size\": 8}, square=True);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vSAAcS2nsic"
      },
      "source": [
        "# Boxplots: looking at the distrbutions of the features  \n",
        "df.Label = df.Label.astype(str)\n",
        "\n",
        "plt.figure(figsize=(25,7))\n",
        "\n",
        "x = \"Label\"\n",
        "ys = [\"Feature_1\", \"Feature_20\", \"Feature_30\", \"Feature_40\", \"Feature_50\"]\n",
        "\n",
        "plt.subplot(151)\n",
        "ax1 = sns.boxplot(x = \"Label\", y = ys[0], notch=True, data=df)\n",
        "add_stat_annotation(ax1, data=df, x=x, y=ys[0],\n",
        "                    box_pairs = [(\"0\",\"1\")],\n",
        "                    test='t-test_ind', text_format='full', loc='inside', verbose=2)\n",
        "\n",
        "\n",
        "plt.subplot(152)\n",
        "ax2 = sns.boxplot(x = \"Label\", y = ys[1], notch=True, data=df)\n",
        "add_stat_annotation(ax2, data=df, x=x, y=ys[1],\n",
        "                    box_pairs = [(\"0\",\"1\")],\n",
        "                    test='t-test_ind', text_format='full', loc='inside', verbose=2)\n",
        "\n",
        "\n",
        "plt.subplot(153)\n",
        "ax3 = sns.boxplot(x = \"Label\", y = ys[2], notch=True, data=df)\n",
        "add_stat_annotation(ax3, data=df, x=x, y=ys[2],\n",
        "                    box_pairs = [(\"0\",\"1\")],\n",
        "                    test='t-test_ind', text_format='full', loc='inside', verbose=2)\n",
        "\n",
        "\n",
        "plt.subplot(154)\n",
        "ax4 = sns.boxplot(x = \"Label\", y = ys[3], notch=True, data=df)\n",
        "add_stat_annotation(ax4, data=df, x=x, y=ys[3],\n",
        "                    box_pairs = [(\"0\",\"1\")],\n",
        "                    test='t-test_ind', text_format='full', loc='inside', verbose=2)\n",
        "\n",
        "plt.subplot(155)\n",
        "ax5 = sns.boxplot(x = \"Label\", y = ys[4], notch=True, data=df)\n",
        "add_stat_annotation(ax5, data=df, x=x, y=ys[4],\n",
        "                    box_pairs = [(\"0\",\"1\")],\n",
        "                    test='t-test_ind', text_format='full', loc='inside', verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJqU783zo9_q"
      },
      "source": [
        "### Feature standardization/ normalization\n",
        "\n",
        "Some of the classifiers do not behave as expected if the features are normalized since they expect a more of less normally distributed data. \n",
        "\n",
        "Therefore we normally ignore the shape of the distribution and just transform the data to center it by removing the mean value of each feature, then scale it by dividing non-constant features by their standard deviation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t82octMmprQ7"
      },
      "source": [
        "# splitting the dataframe df into features, lables and patientids\n",
        "\n",
        "if \"PatientID\" in df.columns:\n",
        "  patientids = df.pop(\"PatientID\")\n",
        "\n",
        "if \"Label\" in df.columns:\n",
        "  labels = df.pop(\"Label\")\n",
        "\n",
        "# normalizing the features by scikit-learn's StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaledFeatures = scaler.fit_transform(df.values)\n",
        "\n",
        "print(f\"Mean of first column: {scaledFeatures[:,0].mean()}, and standard deviation of first column: {scaledFeatures[:,0].std()}\")\n",
        "\n",
        "\n",
        "# Now we rescale these features between 0 and 1. \n",
        "scaler2 = MinMaxScaler()\n",
        "scaled2Features = scaler2.fit_transform(scaledFeatures)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zig0YhvEZcqM"
      },
      "source": [
        "### Feature selection: Selecting K best features based on univariate analysis. \n",
        "\n",
        "There are several feature [selection methods](https://scikit-learn.org/stable/modules/feature_selection.html). Here we perform a simple Univariate feature selection to demonstrate the process of feature selection.  \n",
        "\n",
        "Let's say we want to select 10 best features based on the univariate analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9Cra8xCkk1o"
      },
      "source": [
        "# selecting 10 best features based on chi square test \n",
        "selector = SelectKBest(chi2, k=10)\n",
        "\n",
        "print(f\"Number of features before feature selection: {scaledFeatures.shape[1]}\")\n",
        "\n",
        "selectedFeatures = selector.fit_transform(scaled2Features,labels)\n",
        "\n",
        "print(f\"Number of features after feature selection: {selectedFeatures.shape[1]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSxHLXKxmiDH"
      },
      "source": [
        "# Now let's look at the distribution of couple of these features as before\n",
        "selectedFeatColumns = [f\"SelectedFeat_{i}\" for i in range(10)]\n",
        "selecteddf = pd.DataFrame(selectedFeatures,columns=selectedFeatColumns)\n",
        "selecteddf[\"Label\"] = labels\n",
        "\n",
        "plt.figure(figsize=(15,7))\n",
        "\n",
        "plt.subplot(121)\n",
        "ax1 = sns.boxplot(x = \"Label\", y = \"SelectedFeat_0\", notch=True, data=selecteddf)\n",
        "add_stat_annotation(ax1, data=selecteddf, x=x, y=\"SelectedFeat_0\",\n",
        "                    box_pairs = [(\"0\",\"1\")],\n",
        "                    test='t-test_ind', text_format='full', loc='inside', verbose=2)\n",
        "\n",
        "plt.subplot(122)\n",
        "ax2 = sns.boxplot(x = \"Label\", y = \"SelectedFeat_1\", notch=True, data=selecteddf)\n",
        "add_stat_annotation(ax2, data=selecteddf, x=x, y=\"SelectedFeat_1\",\n",
        "                    box_pairs = [(\"0\",\"1\")],\n",
        "                    test='t-test_ind', text_format='full', loc='inside', verbose=2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mon4_iwMn7ws"
      },
      "source": [
        "***We can notice that these features are discriminable and are found to be statistically signficant between the classes (p<0.05)***\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTtBG-71WNQA"
      },
      "source": [
        "### Machine learning pipeline\n",
        "\n",
        "Now let's try to use these pre-processing steps to create a machine learning piple. \n",
        "\n",
        "Here, we do a 10-fold cross validation on the dataset to demonstrate the results. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFiI-6kUr_sQ"
      },
      "source": [
        "\n",
        "# Partition the data in k folds; by making sure the split is stratified according to the class labels\n",
        "skf = StratifiedKFold(n_splits=10)\n",
        "\n",
        "X = df.values\n",
        "y = labels \n",
        "\n",
        "\n",
        "tprs = []\n",
        "aucs = []\n",
        "mean_fpr = np.linspace(0, 1, 100)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "\n",
        "# looping over different cross validation folds. \n",
        "for i,(train_index, test_index) in enumerate(skf.split(X, y)):\n",
        "\n",
        "  X_train, X_test = X[train_index], X[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "\n",
        "  # difining the classifier along with the pre-processing pipeline.\n",
        "  clf = make_pipeline(StandardScaler(),\n",
        "                MinMaxScaler(),\n",
        "                SelectKBest(chi2,k=30),\n",
        "                LogisticRegression())\n",
        "\n",
        "  # training the classifier on the training set\n",
        "  clf.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "  # evaluating the classifier on the test set and plotting ROC curve \n",
        "  viz = plot_roc_curve(clf, X_test, y_test,\n",
        "                        name=f'ROC fold {i}',\n",
        "                        alpha=0.3, lw=1, ax=ax)\n",
        "  \n",
        "\n",
        "  interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
        "  interp_tpr[0] = 0.0\n",
        "  tprs.append(interp_tpr)\n",
        "  aucs.append(viz.roc_auc)\n",
        "\n",
        "\n",
        "ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
        "        label='Chance', alpha=.8)\n",
        "\n",
        "mean_tpr = np.mean(tprs, axis=0)\n",
        "mean_tpr[-1] = 1.0\n",
        "mean_auc = auc(mean_fpr, mean_tpr)\n",
        "std_auc = np.std(aucs)\n",
        "ax.plot(mean_fpr, mean_tpr, color='b',\n",
        "        label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
        "        lw=2, alpha=.8)\n",
        "\n",
        "std_tpr = np.std(tprs, axis=0)\n",
        "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
        "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
        "ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
        "                label=r'$\\pm$ 1 std. dev.')\n",
        "\n",
        "ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
        "       title=\"ROC Curve\")\n",
        "ax.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClnVDSAJzwqs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}